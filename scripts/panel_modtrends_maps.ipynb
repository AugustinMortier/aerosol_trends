{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this notebook is dedicated to the computation of global map of relative difference / trends of aerosol parameters in between two years both for an ENSEMBLE of models and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules importation\n",
    "from trends_functions import *\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import cartopy.crs as ccrs\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn style\n",
    "sns.set()\n",
    "sns.set_context(\"paper\")\n",
    "# sns.set_style(\"whitegrid\")\n",
    "sns.color_palette(\"muted\")\n",
    "# since each figure will be a subfigure, increase font_size\n",
    "fscale = 1.2\n",
    "sns.set(font_scale=fscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation parameters\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     4,
     10,
     16,
     22,
     28,
     34,
     40,
     46,
     53
    ]
   },
   "outputs": [],
   "source": [
    "# run observations\n",
    "# 'ang4487aer' 'od550aer' 'od550gt1aer' 'od550lt1aer' 'concpm10' 'concpm25' 'sconcso4'\n",
    "var = 'od550aer'\n",
    "params['kind'] = 'obs'\n",
    "params = fill_params(params, var)\n",
    "params['var'] = var\n",
    "obs_source = params['source']\n",
    "reader = pya.io.ReadUngridded(obs_source)\n",
    "obs_data = reader.read(vars_to_retrieve=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Map of relative difference in between two years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#varss = ['od550aer','concpm10']\n",
    "varss = ['od550aer', 'od550lt1aer', 'od550gt1aer', 'ang4487aer', 'concpm10', 'concpm25', 'concso4', 'scatc550dryaer', 'absc550aer']\n",
    "y1, y2 = 2000, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     24,
     26,
     40,
     45,
     50,
     55,
     60,
     65,
     70,
     75
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nl, nc = 3, 3\\nfig, axs = plt.subplots(nl, nc, sharex='col', sharey='row', \\n                       subplot_kw=dict(projection=ccrs.PlateCarree()),\\n                       gridspec_kw={\\n                           'wspace': 0.01,\\n                           'hspace': 0.01\\n                       })\\n# add a big axes, hide frame\\nfig.add_subplot(111, frameon=False)\\nil, ic = 0, 0\\n\\nfor var in varss:\\n    #get models from params\\n    params = fill_params(params, var)\\n\\n    #for the models, set mon_dim to zero\\n    params['min_dim'] = 0\\n    mod_var = params['mod_var']\\n\\n    mod_sources = params['models']\\n    \\n    if 'BCC-CUACE_HIST' in mod_sources:\\n        mod_sources.remove('BCC-CUACE_HIST')\\n\\n    resol = 5\\n    lons = np.arange(-180, 180, resol)\\n    lats = np.arange(-90, 90, resol)\\n    sample_points = [('latitude',lats), ('longitude', lons)]\\n\\n    MOD_DATA = []\\n    for mod_source in mod_sources:\\n        print(var,' - ',mod_source)\\n        params['source'] = mod_source\\n\\n        #check if model in cache\\n        fn = 'cache/'+mod_source+'_'+var+'-'+str(resol)+'x'+str(resol)+'.pkl'\\n        if os.path.isfile(fn):\\n            # for reading also binary mode is important \\n            pklfile = open(fn, 'rb')      \\n            mod_data = pickle.load(pklfile) \\n            pklfile.close()\\n        else:\\n            reader = pya.io.ReadGridded(mod_source)\\n            mod_data = reader.read_var(mod_var, ts_type='daily')\\n            mod_data = mod_data.resample_time(to_ts_type='monthly')\\n            mod_data = mod_data.interpolate(sample_points,scheme='nearest')\\n\\n            #write picke file in cache directory\\n            pklfile = open(fn, 'ab') \\n\\n            # source, destination \\n            pickle.dump(mod_data, pklfile)                      \\n            pklfile.close()\\n\\n        #put model data\\n        MOD_DATA.append(mod_data)\\n    \\n    #compute relative difference between y2 and y1\\n    DIFF = []\\n    nmod = 0\\n    \\n    for i, mod_data in enumerate(MOD_DATA):\\n        year_data = mod_data.resample_time(to_ts_type='yearly')\\n        years = [year.astype(object).year for year in year_data.time_stamps()]\\n\\n        if y1 in years and y2 in years:\\n            iy1 = years.index(y1)\\n            iy2 = years.index(y2)\\n            diff = 100 * (year_data.cube[iy2,:,:] - year_data.cube[iy1,:,:]) / year_data.cube[iy2,:,:]\\n            if not diff.data.mask.all() == True:\\n                nmod+=1\\n                DIFF.append(diff.data)\\n    \\n    #compute the median of the differences\\n    med = np.median(DIFF, axis=0)\\n    \\n    ax = axs[il, ic]\\n    ax.coastlines(zorder=3)\\n    \\n    cmin, cmax = -80, 80\\n    if type(med)!=np.float64 and len(med)>0:\\n        im = ax.contourf(lons,lats,med,levels=np.arange(cmin,cmax+10,10),vmin=cmin,vmax=cmax,transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\\n\\n    #txt = ax.text(0.05,0.95,params['ylabel'],ha='left',va='top',transform=ax.transAxes,fontsize=16,fontweight='bold',zorder=10)\\n    #txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\\n    txt2 = ax.text(0.95,0.05,'n_mod: '+str(nmod),ha='right',va='bottom',transform=ax.transAxes,fontsize=12)\\n    txt2.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\\n    \\n    #remove axis\\n    ax.set_xticks([])\\n    ax.set_yticks([])\\n    ax.set_title(params['ylabel'], ha='left',fontweight='bold')\\n    \\n\\n    #calculates next axis\\n    if ic<nc-1:\\n        ic+=1\\n    else:\\n        il+=1\\n        ic=0\\n\\n#change size of the figure\\n# hide tick and tick label of the big axes\\nplt.tick_params(labelcolor=None, top=False, bottom=False, left=False, right=False)\\nplt.grid(False)\\nplt.xticks([])\\nplt.yticks([])\\n\\nfig.colorbar(im, ax=axs, orientation='horizontal', extend='both',fraction=0.046, pad=0.04)\\n\\nfig.set_size_inches(16,10)\\nfig = plt.gcf()\\n\\n#plt.title('Difference between '+str(y2)+' and '+str(y1))\\nplt.savefig('figs/diff_map.png', dpi=300, bbox_inches='tight')\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''nl, nc = 3, 3\n",
    "fig, axs = plt.subplots(nl, nc, sharex='col', sharey='row', \n",
    "                       subplot_kw=dict(projection=ccrs.PlateCarree()),\n",
    "                       gridspec_kw={\n",
    "                           'wspace': 0.01,\n",
    "                           'hspace': 0.01\n",
    "                       })\n",
    "# add a big axes, hide frame\n",
    "fig.add_subplot(111, frameon=False)\n",
    "il, ic = 0, 0\n",
    "\n",
    "for var in varss:\n",
    "    #get models from params\n",
    "    params = fill_params(params, var)\n",
    "\n",
    "    #for the models, set mon_dim to zero\n",
    "    params['min_dim'] = 0\n",
    "    mod_var = params['mod_var']\n",
    "\n",
    "    mod_sources = params['models']\n",
    "    \n",
    "    if 'BCC-CUACE_HIST' in mod_sources:\n",
    "        mod_sources.remove('BCC-CUACE_HIST')\n",
    "\n",
    "    resol = 5\n",
    "    lons = np.arange(-180, 180, resol)\n",
    "    lats = np.arange(-90, 90, resol)\n",
    "    sample_points = [('latitude',lats), ('longitude', lons)]\n",
    "\n",
    "    MOD_DATA = []\n",
    "    for mod_source in mod_sources:\n",
    "        print(var,' - ',mod_source)\n",
    "        params['source'] = mod_source\n",
    "\n",
    "        #check if model in cache\n",
    "        fn = 'cache/'+mod_source+'_'+var+'-'+str(resol)+'x'+str(resol)+'.pkl'\n",
    "        if os.path.isfile(fn):\n",
    "            # for reading also binary mode is important \n",
    "            pklfile = open(fn, 'rb')      \n",
    "            mod_data = pickle.load(pklfile) \n",
    "            pklfile.close()\n",
    "        else:\n",
    "            reader = pya.io.ReadGridded(mod_source)\n",
    "            mod_data = reader.read_var(mod_var, ts_type='daily')\n",
    "            mod_data = mod_data.resample_time(to_ts_type='monthly')\n",
    "            mod_data = mod_data.interpolate(sample_points,scheme='nearest')\n",
    "\n",
    "            #write picke file in cache directory\n",
    "            pklfile = open(fn, 'ab') \n",
    "\n",
    "            # source, destination \n",
    "            pickle.dump(mod_data, pklfile)                      \n",
    "            pklfile.close()\n",
    "\n",
    "        #put model data\n",
    "        MOD_DATA.append(mod_data)\n",
    "    \n",
    "    #compute relative difference between y2 and y1\n",
    "    DIFF = []\n",
    "    nmod = 0\n",
    "    \n",
    "    for i, mod_data in enumerate(MOD_DATA):\n",
    "        year_data = mod_data.resample_time(to_ts_type='yearly')\n",
    "        years = [year.astype(object).year for year in year_data.time_stamps()]\n",
    "\n",
    "        if y1 in years and y2 in years:\n",
    "            iy1 = years.index(y1)\n",
    "            iy2 = years.index(y2)\n",
    "            diff = 100 * (year_data.cube[iy2,:,:] - year_data.cube[iy1,:,:]) / year_data.cube[iy2,:,:]\n",
    "            if not diff.data.mask.all() == True:\n",
    "                nmod+=1\n",
    "                DIFF.append(diff.data)\n",
    "    \n",
    "    #compute the median of the differences\n",
    "    med = np.median(DIFF, axis=0)\n",
    "    \n",
    "    ax = axs[il, ic]\n",
    "    ax.coastlines(zorder=3)\n",
    "    \n",
    "    cmin, cmax = -80, 80\n",
    "    if type(med)!=np.float64 and len(med)>0:\n",
    "        im = ax.contourf(lons,lats,med,levels=np.arange(cmin,cmax+10,10),vmin=cmin,vmax=cmax,transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "\n",
    "    #txt = ax.text(0.05,0.95,params['ylabel'],ha='left',va='top',transform=ax.transAxes,fontsize=16,fontweight='bold',zorder=10)\n",
    "    #txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "    txt2 = ax.text(0.95,0.05,'n_mod: '+str(nmod),ha='right',va='bottom',transform=ax.transAxes,fontsize=12)\n",
    "    txt2.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "    \n",
    "    #remove axis\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(params['ylabel'], ha='left',fontweight='bold')\n",
    "    \n",
    "\n",
    "    #calculates next axis\n",
    "    if ic<nc-1:\n",
    "        ic+=1\n",
    "    else:\n",
    "        il+=1\n",
    "        ic=0\n",
    "\n",
    "#change size of the figure\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor=None, top=False, bottom=False, left=False, right=False)\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "fig.colorbar(im, ax=axs, orientation='horizontal', extend='both',fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.set_size_inches(16,10)\n",
    "fig = plt.gcf()\n",
    "\n",
    "#plt.title('Difference between '+str(y2)+' and '+str(y1))\n",
    "plt.savefig('figs/diff_map.png', dpi=300, bbox_inches='tight')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first, get location of all observation station available for the different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['od550aer', 'concpm10', 'concso4', 'scatc550dryaer', 'absc550aer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no flags\n",
      "no flags EUROPE station:  ZvenigoroddsEi_GCWD EUROPE station:  HOPE-RWTH-Aachen\n",
      "no flags ASIA station:  Zhongshan_UnivityDh ASIA station:  DRAGON_Soha\n",
      "no flags NAMERICA station:  Yumaowknife_AuroraCYaqui\n",
      "no flags SAMERICA station:  Veracruz_MAX_MEXFOP\n",
      "no flags NAFRICA station:  Zinder_DMNporttutea\n",
      "region:  SAFRICA station:  Walvis_Bay_airport\n",
      "Less than 7 points in selected period\n",
      "no flags\n",
      "no flags AUSTRALIA station:  Tinga_Tinganand_QLD\n",
      "region:  ASIA station:  Petalling JayaI Gentésertrch Observatoryta WORLD station:  DRAGON_Hankuk_UFS station:  FLIN_FLONWORLD station:  Mobile_N_051308W WORLD station:  Namibe WORLD station:  Pantnagar WORLD station:  Pune\n",
      "Less than 7 points in selected period\n",
      "No station found in , SAFRICArraablo de los MontesCyprus Atmospheric Observatory\n",
      "No station found in , AUSTRALIA\n",
      "no flags WORLD station:  Zosenibodenntainstional Park-Lind Point (VI01)n5)tory\n",
      "no flags EUROPE station:  Ähtäri I-III Dam)\n",
      "no flags ASIA station:  TereljRataari (Vachiralongkorn Dam)\n",
      "no flags NAMERICA station:  Zion_Canyon - Turtleback Domey_Run)\n",
      "no flags SAMERICA station:  Virgin_Islands_NP\n",
      "No station found in , SAFRICArrarrota\n",
      "No station found in , AUSTRALIA\n",
      "no flags\n",
      "region:  ASIA station:  Gosanon-domospheric Research Observatoryt\n",
      "Less than 7 points in selected period\n",
      "region:  NAFRICA station:  Granadaiaillonainsderness3ain #1ment (GA09)WA99)5)\n",
      "Less than 7 points in selected period\n",
      "No station found in , AUSTRALIA Point\n",
      "excluding moduletation:  Zeppelin mountain (Ny-Ålesund)1rvatoryA09)WA99)5)\n",
      "excluding modulestation:  Ústí n.L.-mestoic Research Observatoryt\n",
      "region:  ASIA station:  Gual Pahariy\n",
      "Less than 7 points in selected period\n",
      "excluding module\n",
      "excluding moduleA station:  Trinidad Headt Plains E13\n",
      "excluding moduleA station:  Cape San Juan\n",
      "region:  NAFRICA station:  Granadaiailloa\n",
      "Less than 7 points in selected period\n",
      "excluding module\n",
      "No station found in , AUSTRALIA Point\n",
      "excluding module\n",
      "exclude  Alert\n",
      "region:  WORLD station:  Ústí n.L.-mestoin (Ny-Ålesund)ervatoryt\r"
     ]
    }
   ],
   "source": [
    "#read observations\n",
    "OBS = {}\n",
    "\n",
    "for i, var in enumerate(parameters):\n",
    "    # computation parameters\n",
    "    params = get_params()\n",
    "    params['kind'] = 'obs'\n",
    "    fill_params(params, var)\n",
    "\n",
    "    params['var'] = var\n",
    "    obs_source = params['source']\n",
    "    reader = pya.io.ReadUngridded(obs_source)\n",
    "    obs_data = reader.read(vars_to_retrieve=var)\n",
    "    \n",
    "    #compte the trend just to have filtering (300 points, ...)\n",
    "    _, OBS[var], _ = process_trend(\n",
    "        obs_data, params,\n",
    "        plot=False, show_plot=False, save_plot=False, write_json=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### then plot the trends map, with mean over all grid-poiunts, and grid-points where an observation station is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### computation of the trends with only one model\n",
    "varss = ['od550aer', 'od550lt1aer', 'od550gt1aer', 'ang4487aer', 'concpm25', 'concpm10', 'concso4', 'scatc550dryaer', 'absc550aer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_coo(stat_lat, stat_lon, lats, lons):\n",
    "    #this could be done with double list comprehension, but not trivial to pick right indexes afterwards\n",
    "    #d2 = [(stat_lat-lat)**2+(stat_lon-lon)**2 for lat in lats for lon in lons]\n",
    "    \n",
    "    #initialize with large number\n",
    "    min_d2 = 1e10\n",
    "    \n",
    "    #calculates the distance\n",
    "    for i, lat in enumerate(lats):\n",
    "        for j, lon in enumerate(lons):\n",
    "            d2 = (stat_lat-lat)**2 + (stat_lon-lon)**2\n",
    "            if d2<=min_d2:\n",
    "                ilat, ilon = i, j\n",
    "                min_d2 = d2\n",
    "    return ilat, ilon, min_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "od550aer  -  NorESM2-CPL-NEWTEST_HIST\n",
      "35 / 36\n",
      "od550lt1aer  -  NorESM2-CPL-NEWTEST_HIST\n",
      "35 / 36\n",
      "od550gt1aer  -  NorESM2-CPL-NEWTEST_HIST\n",
      "35 / 36\n",
      "ang4487aer  -  NorESM2-CPL-NEWTEST_HIST\n",
      "35 / 36\n",
      "concpm25  -  NorESM2-CPL-NEWTEST_HIST\n",
      "35 / 36\n",
      "concpm10  -  NorESM2-CPL-NEWTEST_HIST\n",
      "35 / 36\n",
      "concso4  -  NorESM2-CPL-NEWTEST_HIST\n",
      "35 / 36\n",
      "scatc550dryaer  -  NorESM2-CPL-NEWTEST_HIST\n",
      "cube has 4 dimension, extract first layer\n",
      "AttributeError\n",
      "35 / 36\n",
      "absc550aer  -  NorESM2-CPL-NEWTEST_HIST\n",
      "cube has 4 dimension, extract first layer\n",
      "AttributeError\n"
     ]
    }
   ],
   "source": [
    "nl, nc = 3, 3\n",
    "fig, axs = plt.subplots(nl, nc, sharex='col', sharey='row', \n",
    "                       subplot_kw=dict(projection=ccrs.PlateCarree()),\n",
    "                       gridspec_kw={\n",
    "                           'wspace': 0.01,\n",
    "                           'hspace': 0.05\n",
    "                       })\n",
    "#add a big axes, hide frame\n",
    "fig.add_subplot(111, frameon=False)\n",
    "il, ic = 0, 0\n",
    "\n",
    "STATS = {}\n",
    "for var in varss:\n",
    "    STATS[var] = {}\n",
    "    \n",
    "    #select available obs dataset\n",
    "    if 'od550' in var or 'ang4487' in var:\n",
    "        obs = OBS['od550aer']\n",
    "    elif 'concpm' in var:\n",
    "        obs = OBS['concpm10']\n",
    "    elif 'concso4' in var:\n",
    "        obs = OBS['concso4']\n",
    "    elif 'scatc' in var:\n",
    "        obs = OBS['scatc550dryaer']\n",
    "    elif 'absc' in var:\n",
    "        obs = OBS['absc550aer']\n",
    "    \n",
    "    params['kind'] = 'mod'\n",
    "    #get models from params\n",
    "    params = fill_params(params, var)\n",
    "    #for the models, set mon_dim to zero\n",
    "    params['min_dim'] = 0\n",
    "    mod_var = params['mod_var']\n",
    "    mod_source = params['ref_model']\n",
    "    \n",
    "    #we assume the pickles files are available\n",
    "    resol = 5\n",
    "    lons = np.arange(-180, 180, resol)\n",
    "    lats = np.arange(-90, 90, resol)\n",
    "    sample_points = [('latitude',lats), ('longitude', lons)]\n",
    "\n",
    "    #if var=='od550aer':\n",
    "    #    mod_source = 'ECMWF_CAMS_REAN'\n",
    "    print(var,' - ',mod_source)\n",
    "    params['source'] = mod_source\n",
    "\n",
    "    slopes, pvals = [], []\n",
    "    if mod_source!=None:\n",
    "        #check if model in cache\n",
    "        fn = 'cache/'+mod_source+'_'+var+'-'+str(resol)+'x'+str(resol)+'.pkl'\n",
    "        if os.path.isfile(fn):\n",
    "            # for reading also binary mode is important \n",
    "            pklfile = open(fn, 'rb')      \n",
    "            mod_data = pickle.load(pklfile) \n",
    "            pklfile.close()\n",
    "        else:\n",
    "            reader = pya.io.ReadGridded(mod_source)\n",
    "            if (var=='scatc550dryaer'):\n",
    "                mod_data = reader.read_var(mod_var, ts_type='daily', aux_fun=pya.io.aux_read_cubes.subtract_cubes, aux_vars=['ec550dryaer', 'absc550aer'])\n",
    "            else:\n",
    "                mod_data = reader.read_var(mod_var, ts_type='daily')\n",
    "            \n",
    "            #crop the cube to interest period, so can handle WORLD region\n",
    "            mod_data = mod_data.crop(time_range=(y1, str(y2)))\n",
    "\n",
    "            #if cube has 4 dimensions, extract first level\n",
    "            if mod_var in ['concso4', 'concpm10', 'concpm25', 'scatc550dryaer', 'absc550aer'] and len(np.shape(mod_data))==4:\n",
    "                print('cube has 4 dimension, extract first layer')\n",
    "                mod_data = mod_data.extract_surface_level()\n",
    "            try:\n",
    "                #write picke file in cache directory\n",
    "                pklfile = open(fn, 'ab') \n",
    "                # source, destination \n",
    "                pickle.dump(mod_data, pklfile)                      \n",
    "                pklfile.close()\n",
    "            except AttributeError:\n",
    "                print('AttributeError')\n",
    "                os.remove(fn)\n",
    "        \n",
    "        mod_data = mod_data.resample_time(to_ts_type='monthly')\n",
    "        mod_data = mod_data.interpolate(sample_points,scheme='nearest')\n",
    "            \n",
    "\n",
    "        #average model data per year\n",
    "        mod_data = mod_data.resample_time(to_ts_type='yearly')\n",
    "\n",
    "        #initialize empty trends\n",
    "        rslopes = np.empty((np.shape(mod_data)[1],np.shape(mod_data)[2]))\n",
    "        aslopes = np.empty((np.shape(mod_data)[1],np.shape(mod_data)[2]))\n",
    "        pvals = np.empty((np.shape(mod_data)[1],np.shape(mod_data)[2]))\n",
    "\n",
    "        rslopes[:] = np.nan\n",
    "        aslopes[:] = np.nan\n",
    "        pvals[:] = np.nan\n",
    "        for ilat in np.arange((np.shape(mod_data)[1])):\n",
    "            print(ilat,'/',np.shape(mod_data)[1], end=\"\\r\")\n",
    "            for ilon in np.arange((np.shape(mod_data)[2])):\n",
    "                x = np.array([int(str(date)[0:4]) for date in mod_data.time_stamps()])\n",
    "                y = np.array(mod_data.data[:,ilat,ilon])\n",
    "\n",
    "                #get indexes within period\n",
    "                iok = [i for i, year in enumerate(x) if year>=y1 and year<=y2]\n",
    "                x = x[iok]\n",
    "                y = y[iok]\n",
    "\n",
    "                if len(x)>2:\n",
    "                    trend = compute_lin_trend(x, y, params)\n",
    "                    rslopes[ilat, ilon] = trend[params['period']]['rel_slp']\n",
    "                    aslopes[ilat, ilon] = trend[params['period']]['a']\n",
    "                    pvals[ilat, ilon] = trend[params['period']]['pval']\n",
    "        print()\n",
    "    \n",
    "    #plot it\n",
    "    ax = axs[il, ic]\n",
    "    ax.coastlines(zorder=3)\n",
    "    \n",
    "    if len(rslopes)>0 and not np.isnan(np.nanmean(rslopes)):\n",
    "        cmin, cmax = -10, 10\n",
    "        if type(rslopes)!=np.float64 and len(rslopes)>0:\n",
    "            im = ax.contourf(lons,lats,rslopes,levels=np.arange(cmin,cmax+1,1),vmin=cmin,vmax=cmax,transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "            \n",
    "            #add points where pvalue is lower than 0.1\n",
    "            for ilon, lon in enumerate(lons):\n",
    "                for ilat, lat in enumerate(lats):\n",
    "                    if pvals[ilat, ilon]<=0.1:\n",
    "                        #ax.plot(lon, lat, 'k.', ms=2)\n",
    "                        if rslopes[ilat, ilon]>0:\n",
    "                            ax.plot(lon, lat, 'r.', ms=2)\n",
    "                        else:\n",
    "                            ax.plot(lon, lat, 'b.', ms=2)\n",
    "\n",
    "        #add text in lower left corner\n",
    "        unit = mod_data.unit.origin\n",
    "        STATS[var]['unit'] = unit\n",
    "        '''\n",
    "        if unit == '1':\n",
    "            str_unit = ''\n",
    "        else:\n",
    "            str_unit = '('+unit+')'\n",
    "        txt = ax.text(0.02,0.12,'$Mean_{2000}'+str_unit+'$',ha='left',va='bottom',transform=ax.transAxes,\n",
    "                       fontsize=12,fontweight='normal',\n",
    "                       color='black',backgroundcolor=bgcolor,\n",
    "                       zorder=99\n",
    "                      )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "        \n",
    "        txt = ax.text(0.02,0.02,'$Trend_{2000-2014}$',ha='left',va='bottom',transform=ax.transAxes,\n",
    "                       fontsize=12,fontweight='normal',\n",
    "                       color='black',backgroundcolor=bgcolor,\n",
    "                       zorder=99\n",
    "                      )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "        '''\n",
    "    \n",
    "        #add mean trend in lower left corner\n",
    "        bgcolor = (1,1,1,0.0)\n",
    "        \n",
    "        #need to use absolute slope for the average calculation\n",
    "        mean_val0 = np.nanmean(mod_data[0,:,:].data) #reference absolute mean\n",
    "        mean_slope = np.nanmean(aslopes)*100/mean_val0\n",
    "        std_slope = np.nanstd(aslopes)*100/mean_val0\n",
    "        STATS[var]['mean_val0'] = mean_val0\n",
    "        STATS[var]['mean_slope'] = mean_slope\n",
    "        STATS[var]['std_slope'] = std_slope\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        #==============================================================================\n",
    "        if mean_slope>0:\n",
    "            fcolor = 'red'\n",
    "        else:\n",
    "            fcolor = 'blue'\n",
    "        #WORLD\n",
    "        txt = ax.text(0.98,0.22,'WORLD',ha='right',va='bottom',transform=ax.transAxes,\n",
    "                       fontsize=12,fontweight='normal',\n",
    "                       color='black',backgroundcolor=bgcolor,\n",
    "                       zorder=99\n",
    "                      )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "        #WORLD MEAN\n",
    "        txt_source = '{:4.2f}'.format(mean_val0)\n",
    "        txt = ax.text(0.98,0.12,txt_source,ha='right',va='bottom',transform=ax.transAxes,\n",
    "                       fontsize=12,fontweight='bold',\n",
    "                       color='black',backgroundcolor=bgcolor,\n",
    "                       zorder=99\n",
    "                      )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "        #WORLD TRENDS\n",
    "        #txt_source = '{:+4.2f}±{:+4.1f}%/yr'.format(mean_slope, std_slope)\n",
    "        txt_source = '{:+4.2f}%/yr'.format(mean_slope)\n",
    "        txt = ax.text(0.98,0.02,txt_source,ha='right',va='bottom',transform=ax.transAxes,\n",
    "                       fontsize=12,fontweight='bold',\n",
    "                       color=fcolor,backgroundcolor=bgcolor,\n",
    "                       zorder=99\n",
    "                      )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "        '''\n",
    "        \n",
    "        #add mean trend@obs station in lower right corner\n",
    "        slope_at_station, val0_at_station = [], []\n",
    "        for station in OBS['od550aer']['WORLD']['stations']:\n",
    "            ilat, ilon, _ = get_closest_coo(station['lat'], station['lon'],lats, lons)\n",
    "            slope_at_station.append(aslopes[ilat, ilon])\n",
    "            val0_at_station.append(mod_data[0, ilat, ilon].data)\n",
    "        mean_val0_at_station = np.nanmean(val0_at_station)\n",
    "        mean_slope_at_station = np.nanmean(slope_at_station)*100/mean_val0_at_station\n",
    "        std_slope_at_station = np.nanstd(slope_at_station)*100/mean_val0_at_station\n",
    "        STATS[var]['mean_val0_at_station'] = mean_val0_at_station\n",
    "        STATS[var]['mean_slope_at_station'] = mean_slope_at_station\n",
    "        STATS[var]['std_slope_at_station'] = std_slope_at_station\n",
    "        \n",
    "        '''\n",
    "        if mean_slope_at_station>0:\n",
    "            fcolor = 'red'\n",
    "        else:\n",
    "            fcolor = 'blue'\n",
    "        #WORLD@stations\n",
    "        txt_source = '{:+4.2f}±{:+4.1f}%/yr'.format(mean_slope_at_station, std_slope_at_station)\n",
    "        txt = ax.text(0.98-0.2,0.22,'WORLD@stations',ha='right',va='bottom',transform=ax.transAxes,\n",
    "                       fontsize=12,fontweight='normal',\n",
    "                       color='black',backgroundcolor=bgcolor,\n",
    "                       zorder=99\n",
    "                      )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "        #WORLD MEAN\n",
    "        txt_source = '{:4.2f}'.format(mean_val0_at_station)\n",
    "        txt = ax.text(0.98-0.2,0.12,txt_source,ha='right',va='bottom',transform=ax.transAxes,\n",
    "                       fontsize=12,fontweight='bold',\n",
    "                       color='black',backgroundcolor=bgcolor,\n",
    "                       zorder=99\n",
    "                      )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "        #WORLD TREND\n",
    "        #txt_source = '{:+4.2f}±{:+4.1f}%/yr'.format(mean_slope_at_station, std_slope_at_station)\n",
    "        txt_source = '{:+4.2f}%/yr'.format(mean_slope_at_station)\n",
    "        txt = ax.text(0.98-0.2,0.02,txt_source,ha='right',va='bottom',transform=ax.transAxes,\n",
    "                       fontsize=12,fontweight='bold',\n",
    "                       color=fcolor, backgroundcolor=bgcolor,\n",
    "                       zorder=99\n",
    "                      )\n",
    "        txt.set_path_effects([PathEffects.withStroke(linewidth=2, foreground='w')])\n",
    "        \n",
    "        #==============================================================================\n",
    "        '''\n",
    "\n",
    "    \n",
    "    #remove axis\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(params['ylabel'], ha='center',fontweight='bold')\n",
    "    \n",
    "\n",
    "    #calculates next axis\n",
    "    if ic<nc-1:\n",
    "        ic+=1\n",
    "    else:\n",
    "        il+=1\n",
    "        ic=0\n",
    "        \n",
    "#change size of the figure\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor=None, top=False, bottom=False, left=False, right=False)\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "#set colorbar\n",
    "cbar = fig.colorbar(im, ax=axs, orientation='horizontal', extend='both',fraction=0.016, pad=0.06, aspect=40)\n",
    "cbar.ax.set_xlabel('Trends in 2000-2014 (%/yr)', fontweight='bold', labelpad=-50)\n",
    "\n",
    "fig.set_size_inches(16,10)\n",
    "fig = plt.gcf()\n",
    "\n",
    "plt.savefig('figs/trends_map2.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the global values in a separate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "thead = ['','Mean WORLD@stations','Mean WORLD', 'Trend WORLD@stations','Trend WORLD']\n",
    "tbody = []\n",
    "'''\n",
    "STATS[var]['mean_val0'] = mean_val0\n",
    "STATS[var]['mean_slope'] = mean_slope\n",
    "STATS[var]['std_slope'] = std_slope\n",
    "'''\n",
    "for var in varss:\n",
    "    if var in ['concpm25', 'concpm10', 'scatc550dryaer', 'absc550aer']:\n",
    "        fmt = '{:2.1f}'\n",
    "    else:\n",
    "        fmt = '{:3.2f}'\n",
    "    fill_params(params, var)\n",
    "    unit = STATS[var]['unit']\n",
    "    if unit == '1':\n",
    "        str_unit = ''\n",
    "    else:\n",
    "        str_unit = ' ('+unit+')'\n",
    "    line = [params['ylabel']+str_unit] + [fmt.format(STATS[var][stat]) for stat in ['mean_val0_at_station', 'mean_val0']] + ['{:+3.2f}'.format(STATS[var][stat]) for stat in ['mean_slope_at_station', 'mean_slope']]\n",
    "    tbody.append(line)\n",
    "    \n",
    "df = pd.DataFrame(tbody, columns=thead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\tophline\n",
      "                    & Mean WORLD@stations & Mean WORLD & Trend WORLD@stations & Trend WORLD \\\\\n",
      "\\middlehline\n",
      "                AOD &                0.16 &       0.14 &                +0.13 &       +0.24 \\\\\n",
      "            AOD<1µm &                0.09 &       0.05 &                +0.42 &       +0.56 \\\\\n",
      "            AOD>1µm &                0.06 &       0.09 &                -0.21 &       +0.07 \\\\\n",
      "                 AE &                0.78 &       0.43 &                +0.21 &       +0.33 \\\\\n",
      "     PM2.5 (ug m-3) &                12.4 &        9.1 &                +0.16 &       +0.20 \\\\\n",
      "      PM10 (ug m-3) &                19.3 &       18.7 &                +0.12 &       +0.08 \\\\\n",
      "       SO4 (ug m-3) &                2.33 &       0.64 &                -1.09 &       +0.38 \\\\\n",
      " Scat. Coef. (1/Mm) &                28.0 &       21.2 &                +0.29 &       +0.20 \\\\\n",
      "  Abs. Coef. (1/Mm) &                 3.1 &        0.9 &                +1.75 &       +1.54 \\\\\n",
      "\\bottomhline\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    latable = df.to_latex(index=False, longtable=False, escape=False)\n",
    "    #replace rule with hline for ACP\n",
    "    latable = latable.replace('toprule','tophline')\n",
    "    latable = latable.replace('midrule','middlehline')\n",
    "    latable = latable.replace('bottomrule','bottomhline')\n",
    "    print(latable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "thead = ['','Mean_{2000}','Trend (\\%/yr)']\n",
    "tbody = []\n",
    "'''\n",
    "STATS[var]['mean_val0'] = mean_val0\n",
    "STATS[var]['mean_slope'] = mean_slope\n",
    "STATS[var]['std_slope'] = std_slope\n",
    "'''\n",
    "for var in varss:\n",
    "    if var in ['concpm25', 'concpm10', 'scatc550dryaer', 'absc550aer']:\n",
    "        fmt = '{:2.1f}'\n",
    "    else:\n",
    "        fmt = '{:3.2f}'\n",
    "    fmt_trend = '{:+3.1f}'\n",
    "    fill_params(params, var)\n",
    "    unit = STATS[var]['unit']\n",
    "    if unit == '1':\n",
    "        str_unit = ''\n",
    "    else:\n",
    "        str_unit = ' ('+unit+')'\n",
    "        str_unit = str_unit.replace('ug','µg')\n",
    "    line = [params['ylabel']+str_unit] + ['('+fmt.format(STATS[var]['mean_val0_at_station'])+') '+fmt.format(STATS[var]['mean_val0'])]  + ['('+fmt_trend.format(STATS[var]['mean_slope_at_station'])+') '+fmt_trend.format(STATS[var]['mean_slope'])] \n",
    "    tbody.append(line)\n",
    "    \n",
    "df = pd.DataFrame(tbody, columns=thead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\tophline\n",
      "                    &  Mean_{2000} & Trend (\\%/yr) \\\\\n",
      "\\middlehline\n",
      "                AOD &  (0.16) 0.14 &   (+0.1) +0.2 \\\\\n",
      "            AOD<1µm &  (0.09) 0.05 &   (+0.4) +0.6 \\\\\n",
      "            AOD>1µm &  (0.06) 0.09 &   (-0.2) +0.1 \\\\\n",
      "                 AE &  (0.78) 0.43 &   (+0.2) +0.3 \\\\\n",
      "     PM2.5 (µg m-3) &   (12.4) 9.1 &   (+0.2) +0.2 \\\\\n",
      "      PM10 (µg m-3) &  (19.3) 18.7 &   (+0.1) +0.1 \\\\\n",
      "       SO4 (µg m-3) &  (2.33) 0.64 &   (-1.1) +0.4 \\\\\n",
      " Scat. Coef. (1/Mm) &  (28.0) 21.2 &   (+0.3) +0.2 \\\\\n",
      "  Abs. Coef. (1/Mm) &    (3.1) 0.9 &   (+1.8) +1.5 \\\\\n",
      "\\bottomhline\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    latable = df.to_latex(index=False, longtable=False, escape=False)\n",
    "    #replace rule with hline for ACP\n",
    "    latable = latable.replace('toprule','tophline')\n",
    "    latable = latable.replace('midrule','middlehline')\n",
    "    latable = latable.replace('bottomrule','bottomhline')\n",
    "    print(latable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/Mm'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data.unit.origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concpm10  -  NorESM2-CPL-NEWTEST_HIST\n"
     ]
    }
   ],
   "source": [
    "var = 'concpm10'\n",
    "STATS[var] = {}\n",
    "\n",
    "#select available obs dataset\n",
    "if 'od550' in var or 'ang4487' in var:\n",
    "    obs = OBS['od550aer']\n",
    "elif 'concpm' in var:\n",
    "    obs = OBS['concpm10']\n",
    "elif 'concso4' in var:\n",
    "    obs = OBS['concso4']\n",
    "elif 'scatc' in var:\n",
    "    obs = OBS['scatc550dryaer']\n",
    "elif 'absc' in var:\n",
    "    obs = OBS['absc550aer']\n",
    "\n",
    "params['kind'] = 'mod'\n",
    "#get models from params\n",
    "params = fill_params(params, var)\n",
    "#for the models, set mon_dim to zero\n",
    "params['min_dim'] = 0\n",
    "mod_var = params['mod_var']\n",
    "mod_source = params['ref_model']\n",
    "\n",
    "#we assume the pickles files are available\n",
    "resol = 5\n",
    "lons = np.arange(-180, 180, resol)\n",
    "lats = np.arange(-90, 90, resol)\n",
    "sample_points = [('latitude',lats), ('longitude', lons)]\n",
    "\n",
    "#if var=='od550aer':\n",
    "#    mod_source = 'ECMWF_CAMS_REAN'\n",
    "print(var,' - ',mod_source)\n",
    "params['source'] = mod_source\n",
    "\n",
    "slopes, pvals = [], []\n",
    "if mod_source!=None:\n",
    "    #check if model in cache\n",
    "    fn = 'cache/'+mod_source+'_'+var+'-'+str(resol)+'x'+str(resol)+'.pkl'\n",
    "    if os.path.isfile(fn):\n",
    "        # for reading also binary mode is important \n",
    "        pklfile = open(fn, 'rb')      \n",
    "        mod_data = pickle.load(pklfile) \n",
    "        pklfile.close()\n",
    "    else:\n",
    "        reader = pya.io.ReadGridded(mod_source)\n",
    "        if (var=='scatc550dryaer'):\n",
    "            mod_data = reader.read_var(mod_var, ts_type='daily', aux_fun=pya.io.aux_read_cubes.subtract_cubes, aux_vars=['ec550dryaer', 'absc550aer'])\n",
    "        else:\n",
    "            mod_data = reader.read_var(mod_var, ts_type='daily')\n",
    "\n",
    "        #crop the cube to interest period, so can handle WORLD region\n",
    "        mod_data = mod_data.crop(time_range=(y1, str(y2)))\n",
    "\n",
    "        #if cube has 4 dimensions, extract first level\n",
    "        if mod_var in ['concso4', 'concpm10', 'concpm25', 'scatc550dryaer', 'absc550aer'] and len(np.shape(mod_data))==4:\n",
    "            print('cube has 4 dimension, extract first layer')\n",
    "            mod_data = mod_data.extract_surface_level()\n",
    "        try:\n",
    "            #write picke file in cache directory\n",
    "            pklfile = open(fn, 'ab') \n",
    "            # source, destination \n",
    "            pickle.dump(mod_data, pklfile)                      \n",
    "            pklfile.close()\n",
    "        except AttributeError:\n",
    "            print('AttributeError')\n",
    "            os.remove(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ug m-3'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
