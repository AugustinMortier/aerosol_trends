{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules importation\n",
    "from trends_functions import *\n",
    "import pickle\n",
    "import os\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn style\n",
    "sns.set()\n",
    "sns.set_context(\"paper\")\n",
    "# sns.set_style(\"whitegrid\")\n",
    "sns.color_palette(\"muted\")\n",
    "# since each figure will be a subfigure, increase font_size\n",
    "fscale = 1.2\n",
    "sns.set(font_scale=fscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# computation parameters\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     4,
     10,
     16,
     22,
     28,
     34,
     40
    ]
   },
   "outputs": [],
   "source": [
    "# run observations\n",
    "# 'ang4487aer' 'od550aer' 'od550gt1aer' 'od550lt1aer' 'concpm10' 'concpm25' 'concso4' 'scatc550dryaer' 'absc550aer'\n",
    "var = 'absc550aer'\n",
    "params['kind'] = 'obs'\n",
    "params = fill_params(params, var)\n",
    "#if var in ['scatc550dryaer', 'absc550aer']:\n",
    "#    params['period'] = '2000-2018'\n",
    "params['var'] = var\n",
    "obs_source = params['source']\n",
    "reader = pya.io.ReadUngridded(obs_source)\n",
    "obs_data = reader.read(vars_to_retrieve=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBS\n",
      "excluding module\n",
      "region:  EUROPE station:  Vavihillmospheric Research Observatoryt\n",
      "Less than 7 points in selected period\n",
      "excluding module\n",
      "region:  ASIA station:  Gosanon-do\n",
      "Less than 7 points in selected period\n",
      "excluding module\n",
      "excluding moduleA station:  Trinidad Headt Plains E13\n",
      "excluding moduleA station:  Cape San Juan\n",
      "exclude  Granada\n",
      "region:  NAFRICA station:  Finokaliaillo\n",
      "Less than 7 points in selected period\n",
      "excluding module\n",
      "No station found in , AUSTRALIA Point\n",
      "excluding module\n",
      "exclude  Alert\n",
      "exclude  Granada\n",
      "region:  WORLD station:  Zeppelin mountain (Ny-Ålesund)ervatoryt\r"
     ]
    }
   ],
   "source": [
    "print('OBS')\n",
    "OBS_TS, OBS_MAP, OBS_DF = process_trend(\n",
    "    obs_data, params,\n",
    "    plot=False, show_plot=False, save_plot=False, write_json=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     7,
     13,
     19,
     25,
     31,
     37,
     43
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NorESM2-CPL-NEWTEST_HIST\n",
      "\n",
      "cube has 4 dimension, extract first layer\n",
      "AttributeError\n"
     ]
    }
   ],
   "source": [
    "params['kind'] = 'mod' \n",
    "params['min_dim'] = 0\n",
    "mod_var = params['mod_var']\n",
    "mod_source = params['ref_model']\n",
    "\n",
    "print(mod_source)\n",
    "print()\n",
    "\n",
    "#check if model in cache\n",
    "fn = 'cache/'+mod_source+'_'+var+'.pkl'\n",
    "if os.path.isfile(fn):\n",
    "    print('use pickle')\n",
    "    # for reading also binary mode is important \n",
    "    pklfile = open(fn, 'rb')      \n",
    "    mod_data = pickle.load(pklfile) \n",
    "    pklfile.close()\n",
    "else:\n",
    "    reader = pya.io.ReadGridded(mod_source)\n",
    "    if (var=='scatc550dryaer'):\n",
    "        mod_data = reader.read_var(mod_var, ts_type='daily', aux_fun=pya.io.aux_read_cubes.subtract_cubes, aux_vars=['ec550dryaer', 'absc550aer'])\n",
    "    else:\n",
    "        mod_data = reader.read_var(mod_var, ts_type='daily')\n",
    "    #if cube has 4 dimensions, extract first level\n",
    "    if mod_var in ['concso4', 'concpm10', 'concpm25', 'scatc550dryaer', 'absc550aer'] and len(np.shape(mod_data))==4:\n",
    "        print('cube has 4 dimension, extract first layer')\n",
    "        mod_data = mod_data.extract_surface_level()\n",
    "    mod_data = mod_data.resample_time(to_ts_type='monthly')\n",
    "\n",
    "    try:\n",
    "        #write picke file in cache directory\n",
    "        pklfile = open(fn, 'ab') \n",
    "\n",
    "        # source, destination \n",
    "        pickle.dump(mod_data, pklfile)                      \n",
    "        pklfile.close()\n",
    "    except AttributeError:\n",
    "        print('AttributeError')\n",
    "        os.remove(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop the cube to interest period, so can handle WORLD region\n",
    "mod_data = mod_data.crop(time_range=(params['period'].split('-')[0], str(int(params['period'].split('-')[1])+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#full colocation\n",
      "colocate monthly dataframes Trinidad Headt Plains E13\n",
      "No station found in  AUSTRALIA\n",
      "colocate monthly dataframesppelin mountain (Ny-Ålesund)ervatoryt\n"
     ]
    }
   ],
   "source": [
    "#full colocation\n",
    "print('#full colocation')\n",
    "MOD_TS, MOD_MAP, MOD_DF = process_trend(\n",
    "    mod_data, params, obs=obs_data,\n",
    "    colocate_time=True, colocate_space=True, \n",
    "    OBS_DF = OBS_DF,\n",
    "    plot=False, show_plot=False, save_plot=False, write_json=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#space colocation only\n",
      "No station found in  AUSTRALIAinidad Headt Plains E13\n",
      "region:  WORLD station:  Zeppelin mountain (Ny-Ålesund)ervatoryt\r"
     ]
    }
   ],
   "source": [
    "#space colocation only\n",
    "print('#space colocation only')\n",
    "ALLTS_MOD_TS, ALLTS_MOD_MAP, ALLTS_MOD_DF = process_trend(\n",
    "    mod_data, params, obs=obs_data, \n",
    "    colocate_time=False, colocate_space=True,\n",
    "    OBS_DF = OBS_DF,\n",
    "    plot=False, show_plot=False, save_plot=False, write_json=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#all pixels in region\n"
     ]
    }
   ],
   "source": [
    "#all pixels in region\n",
    "print('#all pixels in region')\n",
    "REG_MOD_TS, REG_MOD_MAP, REG_MOD_DF = process_trend(\n",
    "    mod_data, params, obs=obs_data, \n",
    "    colocate_time=False, colocate_space=False, \n",
    "    OBS_DF = OBS_DF,\n",
    "    plot=False, show_plot=False, save_plot=False, write_json=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print the results\n",
    "print(' * * OBS * *')\n",
    "print_trends(OBS_MAP)\n",
    "print(' * * MOD * *')\n",
    "print_trends(MOD_MAP)\n",
    "print(' * * ALLTS_MOD * *')\n",
    "print_trends(ALLTS_MOD_MAP)\n",
    "print(' * * REG_MOD * *')\n",
    "print_trends(REG_MOD_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation region by region\n",
    "print(var)\n",
    "print(' * * CONSISTENCY * *')\n",
    "print_consistency(MOD_MAP, ALLTS_MOD_MAP, REG_MOD_MAP, kind='rel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Normal distribution\n",
    "def norm_dist(diff):\n",
    "    norm = 1\n",
    "    mu = 0\n",
    "    stdv = 0.50\n",
    "    gauss = 100*norm*np.exp(-0.5*(((diff-mu)/stdv)**2))\n",
    "    \n",
    "    consistency = gauss\n",
    "    return consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['EUROPE', 'ASIA', 'NAFRICA', 'SAFRICA', 'NAMERICA', 'SAMERICA', 'AUSTRALIA', 'WORLD']\n",
    "MOD = MOD_MAP\n",
    "ALLTS_MOD = ALLTS_MOD_MAP\n",
    "REG_MOD = REG_MOD_MAP\n",
    "key_slope = 'rel_slp'\n",
    "kind = 'rel'\n",
    "\n",
    "tab = []\n",
    "\n",
    "for region in regions:\n",
    "    #get trends keys\n",
    "    try:\n",
    "        periods = MOD[region]['trends']['trends'].keys()\n",
    "    except KeyError:\n",
    "        print(region,'Key Error')\n",
    "        continue\n",
    "    for p, per in enumerate(periods):\n",
    "        try:\n",
    "            r = MOD[region]['trends']['trends'][per]\n",
    "            allts_r = ALLTS_MOD[region]['trends']['trends'][per]\n",
    "            reg_r = REG_MOD[region]['trends']['trends'][per]\n",
    "        except KeyError:\n",
    "            print('\\t',per,'\\t','Key Error')\n",
    "            continue\n",
    "\n",
    "        str_region = region\n",
    "\n",
    "        if r[key_slope]!=None and allts_r[key_slope]:\n",
    "            slp = r[key_slope]\n",
    "            allts_slp = allts_r[key_slope]\n",
    "            reg_slp = reg_r[key_slope]\n",
    "            \n",
    "            time_diff = abs(allts_slp - slp)\n",
    "            space_diff = abs(reg_slp - allts_slp)\n",
    "            all_diff = np.mean([time_diff, space_diff])\n",
    "            \n",
    "            time_consist = norm_dist(time_diff)\n",
    "            space_consist = norm_dist(space_diff)\n",
    "            all_consist = np.mean([time_consist, space_consist])\n",
    "\n",
    "        else:\n",
    "            time_diff = np.nan\n",
    "            space_diff = np.nan\n",
    "            time_consist = np.nan\n",
    "            space_consist = np.nan\n",
    "            all_consist = np.nan\n",
    "            accuracy = np.nan\n",
    "\n",
    "        print(params['ylabel'],str_region, per, \n",
    "              round(slp,1), round(allts_slp,1), round(reg_slp,1), \n",
    "              round(time_diff,1), round(space_diff,1), round(all_diff,1), \n",
    "              round(time_consist,1), round(space_consist,1), round(all_consist,1)\n",
    "             )\n",
    "        tab.append([params['ylabel'],str_region, per, all_consist])\n",
    "        \n",
    "head_df = ['Parameter', 'Region', 'Segment', 'Representativity']\n",
    "df = pd.DataFrame(tab, columns=head_df).set_index(['Parameter', 'Region', 'Segment'])\n",
    "\n",
    "# write dataframe\n",
    "pklfile = open('cache/repr/' + var + '.pkl', 'wb')\n",
    "# source, destination\n",
    "pickle.dump(df, pklfile)\n",
    "pklfile.close()\n",
    "# - - - - - - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-2,2,0.1)\n",
    "y = norm_dist(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4), dpi=100, facecolor='w', edgecolor='k')\n",
    "plt.plot(x, y)\n",
    "\n",
    "#add info in main axis\n",
    "ax = fig.axes[0]\n",
    "ax.set_ylabel('Score (%)')\n",
    "ax.set_xlabel('Trends Absolute Difference (%/yr)')\n",
    "\n",
    "\n",
    "ax.set_facecolor('#F1F1F1')\n",
    "plt.savefig('figs/norm_dist.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "#color area of the curve above n%\n",
    "thr = 50\n",
    "xok, yok = [], []\n",
    "for i, _ in enumerate(y):\n",
    "    if y[i]>=thr:\n",
    "        xok.append(x[i])\n",
    "        yok.append(y[i])\n",
    "\n",
    "plt.fill_between(xok, yok, color='b', alpha=0.2)\n",
    "plt.savefig('figs/norm_dist_filled.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['EUROPE','NAMERICA']\n",
    "regions = ['NAMERICA']\n",
    "\n",
    "#make figure of time series for n regions\n",
    "nl, nc = 2, len(regions)\n",
    "fig, axs = plt.subplots(nl, nc, sharex='col', sharey=False, \n",
    "                       gridspec_kw={\n",
    "                           'wspace': 0.2,\n",
    "                           'hspace': 0.1\n",
    "                       })\n",
    "# add a big axes, hide frame\n",
    "fig.add_subplot(111, frameon=False)\n",
    "\n",
    "current_palette = sns.color_palette()\n",
    "\n",
    "for i, region in enumerate(regions):\n",
    "\n",
    "        \n",
    "    #first figure: number of observations\n",
    "    if len(regions)>1:\n",
    "        ax = axs[0, i]\n",
    "    else:\n",
    "        ax = axs[0]\n",
    "    #ax.set_title(region, fontweight='bold')\n",
    "    ax.text(0.95, 0.85,region,ha='right', fontweight='bold',transform=ax.transAxes)\n",
    "    \n",
    "    #full colocation\n",
    "    odf = OBS_DF[region]\n",
    "    n = odf.count(axis=1, numeric_only=False)\n",
    "    n = n.resample('M', how='mean')\n",
    "    ax.bar(x=n.index, height=n.values, color=current_palette[0], width=1, linewidth=0, zorder=10)\n",
    "    #space colocation\n",
    "    ax.bar(x=n.index, height=[ALLTS_MOD_MAP[region]['nmax'] for i in n.index], color=current_palette[1], width=1, linewidth=0, zorder=9)\n",
    "    #full domain\n",
    "    ax.bar(x=n.index, height=[REG_MOD_MAP[region]['nmax'] for i in n.index], color=current_palette[2], width=1, linewidth=0, zorder=8)\n",
    "    #ax.text(0.97,0.90,'N: {:d}'.format(REG_MOD_MAP[region]['nmax']), color=current_palette[2], ha='right', transform=ax.transAxes)\n",
    "    \n",
    "    \n",
    "    ax.set_facecolor('#F1F1F1')\n",
    "    ax.set_ylabel('Number of Points')\n",
    "    ax.set_xlim('2000-01-01','2015-01-01')\n",
    "    ax.set_ylim(1,1e4)\n",
    "    ax.set_yscale('symlog')\n",
    "    \n",
    "    \n",
    "    #second figure\n",
    "    if len(regions)>1:\n",
    "        ax = axs[1, i]\n",
    "    else:\n",
    "        ax = axs[1]\n",
    "    ax.set_facecolor('#F1F1F1')\n",
    "    #MOD_MAP, ALLTS_MOD_MAP, REG_MOD_MAP\n",
    "    ts1 = MOD_MAP[region]['trends']\n",
    "    ts2 = ALLTS_MOD_MAP[region]['trends']\n",
    "    ts3 = REG_MOD_MAP[region]['trends']\n",
    "    \n",
    "    dy = 0.12\n",
    "    \n",
    "    ax.plot(js2date(ts1['monthly']['jsdate']),ts1['monthly']['data'], ':', lw=1, color=current_palette[0], alpha=0.7)\n",
    "    ax.plot(js2date(ts1['yearly']['jsdate']),ts1['yearly']['data'], '.', ms=8,label='a', color=current_palette[0])\n",
    "    ax.plot(js2date(ts1['trends'][params['period']]['jsdate']),ts1['trends'][params['period']]['data'], ls='-', color=current_palette[0], label='')\n",
    "    ax.text(0.97,0.9,'{:+.1f}%/yr'.format(ts1['trends'][params['period']]['rel_slp']),ha='right',transform=ax.transAxes, color=current_palette[0])\n",
    "    \n",
    "    ax.plot(js2date(ts2['monthly']['jsdate']),ts2['monthly']['data'], ':', lw=1, color=current_palette[1], alpha=0.7)\n",
    "    ax.plot(js2date(ts2['yearly']['jsdate']),ts2['yearly']['data'], '.', ms=8, label='b', color=current_palette[1])\n",
    "    ax.plot(js2date(ts2['trends'][params['period']]['jsdate']),ts2['trends'][params['period']]['data'], ls='-', color=current_palette[1])\n",
    "    ax.text(0.97,0.9-dy,'{:+.1f}%/yr'.format(ts2['trends'][params['period']]['rel_slp']),ha='right',transform=ax.transAxes, color=current_palette[1])\n",
    "    \n",
    "    ax.plot(js2date(ts3['monthly']['jsdate']),ts3['monthly']['data'], ':', lw=1, color=current_palette[2], alpha=0.7)\n",
    "    ax.plot(js2date(ts3['yearly']['jsdate']),ts3['yearly']['data'], '.', ms=8, label='c', color=current_palette[2])\n",
    "    ax.plot(js2date(ts3['trends'][params['period']]['jsdate']),ts3['trends'][params['period']]['data'], ls='-', color=current_palette[2])\n",
    "    ax.text(0.97,0.90-2*dy,'{:+.1f}%/yr'.format(ts3['trends'][params['period']]['rel_slp']),ha='right',transform=ax.transAxes, color=current_palette[2])\n",
    "    \n",
    "    #print out representativity\n",
    "    ax.text(0.97,0.90-3*dy,'Rep: {:.1f}%'.format(df['Representativity'][params['ylabel']][region][params['period']]),ha='right',fontweight='bold', transform=ax.transAxes)\n",
    "    \n",
    "    \n",
    "    ax.set_ylim(0,0.3)\n",
    "    ax.set_ylim(0,3)\n",
    "    ax.set_xlim('2000-01-01','2015-01-01')\n",
    "    ax.set_ylabel(params['ylabel'])\n",
    "\n",
    "#change size of the figure\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor=None, top=False, bottom=False, left=False, right=False)\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labels = ['$Ref_{time}$: space and time colocation', '$Exp_{time} / Ref_{space}$: space colocation', '$Exp_{space}$: full domain']\n",
    "fig.legend(handles, labels, loc='lower center', ncol=3, facecolor='white')\n",
    "\n",
    "fig.set_size_inches(16,7)\n",
    "fig = plt.gcf()\n",
    "plt.savefig('figs/representativity-'+var+'.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
